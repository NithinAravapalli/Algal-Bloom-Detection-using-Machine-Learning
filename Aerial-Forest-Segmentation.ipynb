{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.data as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:13.060127Z",
     "iopub.status.busy": "2024-03-31T03:24:13.059160Z",
     "iopub.status.idle": "2024-03-31T03:24:31.811552Z",
     "shell.execute_reply": "2024-03-31T03:24:31.810109Z",
     "shell.execute_reply.started": "2024-03-31T03:24:13.060086Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"Dataset/Forest Segmented/images/\"\n",
    "MASK_DIR = \"Dataset/Forest Segmented/masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = int(1e3)\n",
    "AUTOTUNE = tfd.AUTOTUNE\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.clip_by_value(image, clip_value_min = 0.0, clip_value_max = 1.0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_masks(file_path):\n",
    "    mask_image = decode_image(file_path)\n",
    "    mask_image = mask_image[:, :, :1]  # Keep only the first channel for binary masks\n",
    "    return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title=None, alpha=1):\n",
    "    plt.imshow(image, alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_masks(dataset, n_rows=5, n_cols=3, figsize=(10, 15)):\n",
    "    images, masks = next(iter(dataset.take(1)))\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(1, (n_rows * n_cols) + 1, n_cols):\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        show_image(images[i], title=\"Aerial Imagery\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        show_image(masks[i], title=\"Image Mask\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i + 2)\n",
    "        show_image(images[i])\n",
    "        show_image(masks[i], alpha=0.5, title=\"Overlapping\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"Dataset/meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.image = metadata.image.apply(lambda file_name: f\"{IMAGE_DIR}{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['mask'] = metadata['mask'].apply(lambda file_name: f\"{MASK_DIR}{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = tfd.Dataset.from_tensor_slices(metadata['image'])\n",
    "mask_files = tfd.Dataset.from_tensor_slices(metadata['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = image_files.map(decode_image)\n",
    "masks = mask_files.map(decode_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip((images, masks))\n",
    "dataset = dataset.repeat(2).shuffle(1000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:32.040414Z",
     "iopub.status.busy": "2024-03-31T03:24:32.040129Z",
     "iopub.status.idle": "2024-03-31T03:24:35.098003Z",
     "shell.execute_reply": "2024-03-31T03:24:35.097032Z",
     "shell.execute_reply.started": "2024-03-31T03:24:32.040389Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image_masks(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:35.099587Z",
     "iopub.status.busy": "2024-03-31T03:24:35.099259Z",
     "iopub.status.idle": "2024-03-31T03:24:35.107345Z",
     "shell.execute_reply": "2024-03-31T03:24:35.106404Z",
     "shell.execute_reply.started": "2024-03-31T03:24:35.099559Z"
    }
   },
   "outputs": [],
   "source": [
    "class Augment(layers.Layer):\n",
    "    def __init__(self, seed=42):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.augment_images = tf.keras.Sequential([\n",
    "            layers.RandomRotation(0.3, seed=seed),\n",
    "            layers.RandomFlip(mode=\"horizontal\", seed=seed),\n",
    "        ])\n",
    "        \n",
    "        self.augment_masks = tf.keras.Sequential([\n",
    "            layers.RandomRotation(0.3, seed=seed),\n",
    "            layers.RandomFlip(mode=\"horizontal\", seed=seed),\n",
    "        ])\n",
    "            \n",
    "    def call(self, inputs, labels):\n",
    "        inputs = self.augment_images(inputs)\n",
    "        labels = self.augment_masks(labels)\n",
    "        return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_ds = dataset.map(Augment(SEED)).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:35.108783Z",
     "iopub.status.busy": "2024-03-31T03:24:35.108476Z",
     "iopub.status.idle": "2024-03-31T03:24:38.132699Z",
     "shell.execute_reply": "2024-03-31T03:24:38.131717Z",
     "shell.execute_reply.started": "2024-03-31T03:24:35.108755Z"
    }
   },
   "outputs": [],
   "source": [
    "show_image_masks(augmented_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(augmented_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in the augmented dataset:\", total_samples * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = augmented_ds.take(VALIDATION_SIZE//BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "train_ds = augmented_ds.skip(VALIDATION_SIZE//BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = tfd.experimental.cardinality(train_ds).numpy() * BATCH_SIZE\n",
    "valid_samples = tfd.experimental.cardinality(valid_ds).numpy() * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training   Samples:\", train_samples)\n",
    "print(\"Validation Samples:\", valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tensorflow.keras.applications.MobileNetV2(\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tensorflow.keras.Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=base_model_outputs,\n",
    "    name=\"Encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:38.257549Z",
     "iopub.status.busy": "2024-03-31T03:24:38.257250Z",
     "iopub.status.idle": "2024-03-31T03:24:39.348741Z",
     "shell.execute_reply": "2024-03-31T03:24:39.347714Z",
     "shell.execute_reply.started": "2024-03-31T03:24:38.257524Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:39.350334Z",
     "iopub.status.busy": "2024-03-31T03:24:39.350021Z",
     "iopub.status.idle": "2024-03-31T03:24:39.370027Z",
     "shell.execute_reply": "2024-03-31T03:24:39.368950Z",
     "shell.execute_reply.started": "2024-03-31T03:24:39.350308Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:39.371433Z",
     "iopub.status.busy": "2024-03-31T03:24:39.371166Z",
     "iopub.status.idle": "2024-03-31T03:24:39.382357Z",
     "shell.execute_reply": "2024-03-31T03:24:39.381468Z",
     "shell.execute_reply.started": "2024-03-31T03:24:39.371411Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(encoder_block, decoder_block, output_channels=1, **kwargs):\n",
    "    inputs = keras.Input(shape=(*IMAGE_SIZE, 3), name=\"ImageInput\")\n",
    "    encodings = encoder_block(inputs)\n",
    "    skips = reversed(encodings[:-1])        \n",
    "    encoding = encodings[-1]\n",
    "    for index, (up, skip) in enumerate(zip(decoder_block, skips)):\n",
    "        encoding = up(encoding)\n",
    "        encoding = layers.Concatenate(name=f\"ConCat-{index+1}\")([encoding, skip])\n",
    "    mask_out = layers.Conv2DTranspose(\n",
    "        filters=1,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "    )(encoding)\n",
    "    \n",
    "    mask_out = layers.Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=1,\n",
    "        padding=\"same\",\n",
    "        activation='sigmoid',\n",
    "        name=\"MaskOut\"\n",
    "    )(mask_out)\n",
    "    model = keras.Model(inputs, mask_out, **kwargs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:39.383819Z",
     "iopub.status.busy": "2024-03-31T03:24:39.383531Z",
     "iopub.status.idle": "2024-03-31T03:24:39.523461Z",
     "shell.execute_reply": "2024-03-31T03:24:39.522526Z",
     "shell.execute_reply.started": "2024-03-31T03:24:39.383794Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(encoder, decoder, name=\"create_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred_masks(dataset, model, n_rows=5, n_cols=6, figsize=(15, 15), savepath=None):\n",
    "    images, masks = next(iter(dataset.take(1)))\n",
    "    pred_masks = model.predict(images)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(1, (n_rows * n_cols) + 1, n_cols):\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        show_image(images[i], title=\"Aerial Imagery\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        show_image(masks[i], title=\"True Image Mask\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, i + 2)\n",
    "        show_image(pred_masks[i], title=\"Predicted Image Mask\")\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i + 3)\n",
    "        show_image(tf.cast(pred_masks[i]>=0.5, tf.float32), title=\"Processed Mask(0.5)\")\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i + 4)\n",
    "        show_image(tf.cast(pred_masks[i]>=0.7, tf.float32), title=\"Processed Mask(0.7)\")\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, i + 5)\n",
    "        show_image(images[i])\n",
    "        show_image(pred_masks[i], alpha=0.5, title=\"Overlapping\")\n",
    "        \n",
    "        \n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:24:39.525163Z",
     "iopub.status.busy": "2024-03-31T03:24:39.524776Z",
     "iopub.status.idle": "2024-03-31T03:24:39.546941Z",
     "shell.execute_reply": "2024-03-31T03:24:39.545948Z",
     "shell.execute_reply.started": "2024-03-31T03:24:39.525128Z"
    }
   },
   "outputs": [],
   "source": [
    "class ShowImageMasksCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_pred_masks(dataset=self.dataset, n_rows=3, model=self.model, savepath=f\"ModelPred_Epoch_{epoch}.png\", figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_samples//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_train = False\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if can_train:\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[ShowImageMasksCallback(valid_ds)]\n",
    ")\n",
    "    model.save(\"Aerial-Forest-Segmentation.keras\")\n",
    "    with open(\"Aerial-Forest-Segmentation.pickle\", \"wb\") as fs:\n",
    "        pickle.dump(history.history)\n",
    "    history = history.history\n",
    "else:\n",
    "    model = load_model(\"Aerial-Forest-Segmentation.keras\")\n",
    "    with open(\"Aerial-Forest-Segmentation.pickle\", \"rb\") as fs:\n",
    "        history = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred_masks(valid_ds.shuffle(500), model=model, n_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred_masks(valid_ds.shuffle(500), model=model, n_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-31T03:42:07.580841Z",
     "iopub.status.busy": "2024-03-31T03:42:07.579961Z",
     "iopub.status.idle": "2024-03-31T03:42:16.230928Z",
     "shell.execute_reply": "2024-03-31T03:42:16.229922Z",
     "shell.execute_reply.started": "2024-03-31T03:42:07.580806Z"
    }
   },
   "outputs": [],
   "source": [
    "show_pred_masks(valid_ds.shuffle(500), model=model, n_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-03-31T03:59:02.010090Z",
     "iopub.status.busy": "2024-03-31T03:59:02.009344Z",
     "iopub.status.idle": "2024-03-31T03:59:05.428431Z",
     "shell.execute_reply": "2024-03-31T03:59:05.427293Z",
     "shell.execute_reply.started": "2024-03-31T03:59:02.010054Z"
    }
   },
   "outputs": [],
   "source": [
    "figsize = (20, 20)\n",
    "n_rows, n_cols = 3, 5\n",
    "\n",
    "images, masks = next(iter(train_ds.shuffle(1000).take(1)))\n",
    "pred_masks = model.predict(images)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(1, (n_rows * n_cols) + 1, n_cols):\n",
    "\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    show_image(images[i], title=\"Aerial Imagery\")\n",
    "    \n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    show_image(images[i])\n",
    "    show_image(masks[i], alpha=0.6, title=\"True Mask\")\n",
    "    \n",
    "    plt.subplot(n_rows, n_cols, i + 2)\n",
    "    show_image(images[i])\n",
    "    show_image(pred_masks[i]>=0.5, alpha=0.6, title=\"Overlapping (0.5)\")\n",
    "    \n",
    "    plt.subplot(n_rows, n_cols, i + 3)\n",
    "    show_image(images[i])\n",
    "    show_image(pred_masks[i]>=0.7, alpha=0.6, title=\"Overlapping (0.7)\")\n",
    "    \n",
    "    plt.subplot(n_rows, n_cols, i + 4)\n",
    "    show_image(images[i])\n",
    "    show_image(pred_masks[i]>=0.9, alpha=0.6, title=\"Overlapping (0.9)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1650618,
     "sourceId": 2738848,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
